{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1749268776739,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "sm58JXiuQNs5",
    "outputId": "e1d376b3-62a0-47fd-f430-8035dd3bb0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\programdata\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4862,
     "status": "ok",
     "timestamp": 1749268781627,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "VUbdqNcvQDME",
    "outputId": "00c24a6b-fb93-44fa-bc95-efe9a493e81d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679cfdb8fc50484db9881133cb076c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a85e27ddbe4ac7aba13c322acb7605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decf1b26128e427c827bf84307278083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/813k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448b30c4ff8140b291c1719d6c6bb2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f58d7fe2bdd452391639788d0367cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dai.STUDENTSDC\\.conda\\envs\\NLP\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf21f37834fd422aaec23cd01f69d5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589f09be8e8745e99b32dd2190bd97c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi: मशीन लर्निंग दुनिया को बदल रही है।\n",
      " English: The machine's changing the world.\n"
     ]
    }
   ],
   "source": [
    "# Machine translation (Language translation)\n",
    "\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-hi-en\"\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate(text):\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    outputs = model.generate (**inputs)\n",
    "\n",
    "    return tokenizer.decode(outputs [0], skip_special_tokens=True)\n",
    "\n",
    "#Example Hindi text\n",
    "\n",
    "hindi_text = \"मशीन लर्निंग दुनिया को बदल रही है।\" #     \"यंत्र अधिगम दुनिया को बदल रही है।\"\n",
    "\n",
    "translated_text = translate(hindi_text)\n",
    "\n",
    "print(f\"Hindi: {hindi_text}\\n English: {translated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2332,
     "status": "ok",
     "timestamp": 1749268783971,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "XNh262iHRWtn",
    "outputId": "ce0948f5-4b82-4572-8501-7ea11f04d523"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9e5037b857458883496993c9576542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba32f559956c4944b3242136e6871587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c8aa4175ef4108ba6a733e7cf943c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6258b704f8d48dfb89cbde3353bf203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d1f459e97d4f5db8d6df391d46b7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9efc5c36cde4b658118eb285e8f1e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e6d7df5e044b3994a7b41135355fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37df4b7a34e4b48af4fee3db91c96b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English : Machine Learning is changing the world.\n",
      " Hindi : मशीन सीखना दुनिया बदल रहा है.\n"
     ]
    }
   ],
   "source": [
    "# English to Hindi\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate(text):\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    outputs = model.generate (**inputs)\n",
    "\n",
    "    return tokenizer.decode(outputs [0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "eng_text = \"Machine Learning is changing the world.\"\n",
    "\n",
    "translated_text = translate(eng_text)\n",
    "\n",
    "print(f\"English : {eng_text}\\n Hindi : {translated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1152,
     "status": "ok",
     "timestamp": 1749268785137,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "4yznNEZ7Shdr",
    "outputId": "d52600ce-2fb9-492a-fbcc-fe78d5d4b8c7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad6cc777c22444eac183f800dbf279e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English : We all are trying to learn AI here.\n",
      "Hindi : हम सब यहाँ एआई को सीखने की कोशिश कर रहे हैं.\n"
     ]
    }
   ],
   "source": [
    "eng_text = \"We all are trying to learn AI here.\"\n",
    "\n",
    "translated_text = translate(eng_text)\n",
    "\n",
    "print(f\"English : {eng_text}\\nHindi : {translated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22904,
     "status": "ok",
     "timestamp": 1749268808058,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "s_VjA0EHSsri",
    "outputId": "7f33b632-89e5-49c0-a655-980fd6b38270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating.....\n",
      "\n",
      "[1] ज़रूर मिला\n",
      "\n",
      "[2] सी.\n",
      "\n",
      "[3] . . .\n",
      "\n",
      "[4] . . .\n",
      "\n",
      "[6] सेल\n",
      "\n",
      "[7] एनईएसडी\n",
      "\n",
      "[8] नोबल गैस\n",
      "\n",
      "[9] . . .\n",
      "\n",
      "[10] ए.\n",
      "\n",
      "[11] . . .\n",
      "\n",
      "[12] बि.\n",
      "\n",
      "[14] बी.\n",
      "\n",
      "[15] एन.\n",
      "\n",
      "[16] . . .\n",
      "\n",
      "[17] ए.\n",
      "\n",
      "[18] अंक\n",
      "\n",
      "[19] प्रति\n",
      "\n",
      "[21] एडी\n",
      "\n",
      "[22] हे.\n",
      "\n",
      "[24] world. kgm\n",
      "\n",
      "[25] बी.\n",
      "\n",
      "[26] सेल\n",
      "\n",
      "[28] एनईएसडी\n",
      "\n",
      "[29] ू\n",
      "\n",
      "[30] . . .\n",
      "\n",
      "[32] ू\n",
      "\n",
      "[33] . . .\n",
      "\n",
      "[34] .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate(text):\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True,\n",
    "                       truncation=True, max_length = 512)\n",
    "\n",
    "    outputs = model.generate (**inputs)\n",
    "\n",
    "    return tokenizer.decode(outputs [0], skip_special_tokens=True)\n",
    "\n",
    "def fetch_hindi_wikipedia_article(url):\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    content_div = soup.find('div', {'class': 'mw-parser-output'})\n",
    "\n",
    "    paragraphs = content_div.find_all('p')\n",
    "\n",
    "    hindi_texts = [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)]\n",
    "\n",
    "    return hindi_text\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Artificial_intelligence\"\n",
    "\n",
    "hindi_paragraph = fetch_hindi_wikipedia_article(url)\n",
    "\n",
    "print(\"Translating.....\\n\")\n",
    "\n",
    "for i, para in enumerate(hindi_paragraph):\n",
    "\n",
    "    try:\n",
    "\n",
    "        if len(para.strip()) > 0:\n",
    "\n",
    "            translated = translate(para)\n",
    "\n",
    "            print(f\"[{i+1}] {translated}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"[{i+1}] skipped due to error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5324,
     "status": "ok",
     "timestamp": 1749268813397,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "p3K_gaR3bOju",
    "outputId": "15cd8817-3eea-4bba-a8ba-0bae39e2be14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
      "Collecting requests>=2.26.0\n",
      "  Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dai.studentsdc\\appdata\\roaming\\python\\python38\\site-packages (from SpeechRecognition) (4.13.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.25.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.2-cp38-cp38-win_amd64.whl (105 kB)\n",
      "Installing collected packages: charset-normalizer, requests, SpeechRecognition\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.24.0\n",
      "    Uninstalling requests-2.24.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\requests-2.24.0.dist-info\\\\direct_url.json'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13969,
     "status": "ok",
     "timestamp": 1749268827370,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "BqP5HYO2c46U",
    "outputId": "9d8a7ff4-7015-47bf-bb3c-d442087f56a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp38-cp38-win_amd64.whl (164 kB)\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "error",
     "timestamp": 1749268827427,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "QlU1cNiJa09W",
    "outputId": "71c9368a-b25a-4b11-f3e8-75aafae031a1"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No Default Input Device Available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m recognizer = sr. Recognizer()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#Capture audio from microphone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMicrophone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSpeak something...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m     recognizer.adjust_for_ambient_noise(source)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dai.STUDENTSDC\\.conda\\envs\\NLP\\Lib\\site-packages\\speech_recognition\\__init__.py:82\u001b[39m, in \u001b[36mMicrophone.__init__\u001b[39m\u001b[34m(self, device_index, sample_rate, chunk_size)\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m0\u001b[39m <= device_index < count, \u001b[33m\"\u001b[39m\u001b[33mDevice index out of range (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m devices available; device index should be between 0 and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m inclusive)\u001b[39m\u001b[33m\"\u001b[39m.format(count, count - \u001b[32m1\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# automatically set the sample rate to the hardware's default sample rate if not specified\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     device_info = audio.get_device_info_by_index(device_index) \u001b[38;5;28;01mif\u001b[39;00m device_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43maudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_default_input_device_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device_info.get(\u001b[33m\"\u001b[39m\u001b[33mdefaultSampleRate\u001b[39m\u001b[33m\"\u001b[39m), (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m device_info[\u001b[33m\"\u001b[39m\u001b[33mdefaultSampleRate\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mInvalid device info returned from PyAudio: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(device_info)\n\u001b[32m     84\u001b[39m     sample_rate = \u001b[38;5;28mint\u001b[39m(device_info[\u001b[33m\"\u001b[39m\u001b[33mdefaultSampleRate\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dai.STUDENTSDC\\.conda\\envs\\NLP\\Lib\\site-packages\\pyaudio\\__init__.py:812\u001b[39m, in \u001b[36mPyAudio.get_default_input_device_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_default_input_device_info\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    804\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns the default input device parameters as a dictionary.\u001b[39;00m\n\u001b[32m    805\u001b[39m \n\u001b[32m    806\u001b[39m \u001b[33;03m    The keys of the dictionary mirror the data fields of PortAudio's\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    810\u001b[39m \u001b[33;03m    :rtype: dict\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m     device_index = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_default_input_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_device_info_by_index(device_index)\n",
      "\u001b[31mOSError\u001b[39m: No Default Input Device Available"
     ]
    }
   ],
   "source": [
    "# Automatic speech Recognition\n",
    "\n",
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "\n",
    "recognizer = sr. Recognizer()\n",
    "\n",
    "#Capture audio from microphone\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "\n",
    "    print(\"Speak something...\")\n",
    "\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "    audio = recognizer.listen(source)\n",
    "\n",
    "try:\n",
    "\n",
    "    text = recognizer.recognize_google(audio) # Convert speech to text\n",
    "\n",
    "    print(\"You said : \", text)\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "\n",
    "    print(\"Sorry, could not understand the audio\")\n",
    "\n",
    "except sr.RequestError:\n",
    "\n",
    "    print(\"Could not request results, check your internet connection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4193,
     "status": "ok",
     "timestamp": 1749268837086,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "7FXQMe8IYLDF",
    "outputId": "8d4744fa-6e71-4c99-c53f-4222f4b64d99"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/harvard.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      9\u001b[39m recognizer = sr.Recognizer()\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#Load the WAV file\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#We can get clear.wav files from here:  https://www.voiptroubleshooter.com/open_speech/american.html\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# https://www.kaggle.com/datasets/pavanelisetty/sample-audio-files-for-speech-recognition\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAudioFile\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/content/harvard.wav\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43maudio_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#Recognize speech\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dai.STUDENTSDC\\.conda\\envs\\NLP\\Lib\\site-packages\\speech_recognition\\__init__.py:233\u001b[39m, in \u001b[36mAudioFile.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mThis audio source is already inside a context manager\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    232\u001b[39m     \u001b[38;5;66;03m# attempt to read the file as WAV\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     \u001b[38;5;28mself\u001b[39m.audio_reader = \u001b[43mwave\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilename_or_fileobject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m     \u001b[38;5;28mself\u001b[39m.little_endian = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (wave.Error, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dai.STUDENTSDC\\.conda\\envs\\NLP\\Lib\\wave.py:630\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(f, mode)\u001b[39m\n\u001b[32m    628\u001b[39m         mode = \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWave_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Wave_write(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dai.STUDENTSDC\\.conda\\envs\\NLP\\Lib\\wave.py:280\u001b[39m, in \u001b[36mWave_read.__init__\u001b[39m\u001b[34m(self, f)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28mself\u001b[39m._i_opened_the_file = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     f = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28mself\u001b[39m._i_opened_the_file = f\n\u001b[32m    282\u001b[39m \u001b[38;5;66;03m# else, assume it is an open file object already\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/harvard.wav'"
     ]
    }
   ],
   "source": [
    "# Automatic Speech Recognition (ASR)\n",
    "\n",
    "#pip install SpeechRecognition\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Initialize recognizer\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "#Load the WAV file\n",
    "\n",
    "#We can get clear.wav files from here:  https://www.voiptroubleshooter.com/open_speech/american.html\n",
    "\n",
    "# https://www.kaggle.com/datasets/pavanelisetty/sample-audio-files-for-speech-recognition\n",
    "\n",
    "with sr.AudioFile(\"/content/harvard.wav\") as source:\n",
    "\n",
    "    audio_data = recognizer.record(source)\n",
    "\n",
    "\n",
    "#Recognize speech\n",
    "\n",
    "try:\n",
    "\n",
    "    text = recognizer.recognize_google(audio_data)\n",
    "\n",
    "    print(\"Transcription:\", text)\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "\n",
    "    print(\"Sorry, could not understand the audio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7494,
     "status": "ok",
     "timestamp": 1749268846663,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "ST6d_v22gfey",
    "outputId": "6bf00ff8-51e4-4cf2-a60c-e2b5226fa57f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.11/dist-packages (2.98)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12540,
     "status": "ok",
     "timestamp": 1749268879188,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "1hB0MdVDg61y",
    "outputId": "d2151673-258c-43f4-c839-7c692bab9679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
      "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "espeak is already the newest version (1.48.15+dfsg-3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install espeak -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1749268881298,
     "user": {
      "displayName": "Kishan Prakash",
      "userId": "00782312557775250381"
     },
     "user_tz": -330
    },
    "id": "oe1rk8pZgI_o",
    "outputId": "a957ea8e-5834-4364-ad90-ba80c765eba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice 0: afrikaans - afrikaans\n",
      "Voice 1: aragonese - aragonese\n",
      "Voice 2: bulgarian - bulgarian\n",
      "Voice 3: bengali - bengali\n",
      "Voice 4: bosnian - bosnian\n",
      "Voice 5: catalan - catalan\n",
      "Voice 6: czech - czech\n",
      "Voice 7: welsh - welsh\n",
      "Voice 8: danish - danish\n",
      "Voice 9: german - german\n",
      "Voice 10: greek - greek\n",
      "Voice 11: default - default\n",
      "Voice 12: english - english\n",
      "Voice 13: en-scottish - en-scottish\n",
      "Voice 14: english-north - english-north\n",
      "Voice 15: english_rp - english_rp\n",
      "Voice 16: english_wmids - english_wmids\n",
      "Voice 17: english-us - english-us\n",
      "Voice 18: en-westindies - en-westindies\n",
      "Voice 19: esperanto - esperanto\n",
      "Voice 20: spanish - spanish\n",
      "Voice 21: spanish-latin-am - spanish-latin-am\n",
      "Voice 22: estonian - estonian\n",
      "Voice 23: basque-test - basque-test\n",
      "Voice 24: Persian+English-UK - Persian+English-UK\n",
      "Voice 25: Persian+English-US - Persian+English-US\n",
      "Voice 26: persian-pinglish - persian-pinglish\n",
      "Voice 27: finnish - finnish\n",
      "Voice 28: french-Belgium - french-Belgium\n",
      "Voice 29: french - french\n",
      "Voice 30: irish-gaeilge - irish-gaeilge\n",
      "Voice 31: greek-ancient - greek-ancient\n",
      "Voice 32: gujarati-test - gujarati-test\n",
      "Voice 33: hindi - hindi\n",
      "Voice 34: croatian - croatian\n",
      "Voice 35: hungarian - hungarian\n",
      "Voice 36: armenian - armenian\n",
      "Voice 37: armenian-west - armenian-west\n",
      "Voice 38: interlingua - interlingua\n",
      "Voice 39: indonesian - indonesian\n",
      "Voice 40: icelandic - icelandic\n",
      "Voice 41: italian - italian\n",
      "Voice 42: lojban - lojban\n",
      "Voice 43: georgian - georgian\n",
      "Voice 44: kannada - kannada\n",
      "Voice 45: kurdish - kurdish\n",
      "Voice 46: latin - latin\n",
      "Voice 47: lingua_franca_nova - lingua_franca_nova\n",
      "Voice 48: lithuanian - lithuanian\n",
      "Voice 49: latvian - latvian\n",
      "Voice 50: macedonian - macedonian\n",
      "Voice 51: malayalam - malayalam\n",
      "Voice 52: malay - malay\n",
      "Voice 53: nepali - nepali\n",
      "Voice 54: dutch - dutch\n",
      "Voice 55: norwegian - norwegian\n",
      "Voice 56: punjabi - punjabi\n",
      "Voice 57: polish - polish\n",
      "Voice 58: brazil - brazil\n",
      "Voice 59: portugal - portugal\n",
      "Voice 60: romanian - romanian\n",
      "Voice 61: russian - russian\n",
      "Voice 62: slovak - slovak\n",
      "Voice 63: albanian - albanian\n",
      "Voice 64: serbian - serbian\n",
      "Voice 65: swedish - swedish\n",
      "Voice 66: swahili-test - swahili-test\n",
      "Voice 67: tamil - tamil\n",
      "Voice 68: telugu-test - telugu-test\n",
      "Voice 69: turkish - turkish\n",
      "Voice 70: vietnam - vietnam\n",
      "Voice 71: vietnam_hue - vietnam_hue\n",
      "Voice 72: vietnam_sgn - vietnam_sgn\n",
      "Voice 73: Mandarin - Mandarin\n",
      "Voice 74: cantonese - cantonese\n"
     ]
    }
   ],
   "source": [
    "#Text-to-Speech (TTS)\n",
    "\n",
    "import pyttsx3\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "engine.say(\"Hellol How can I assist you?\")\n",
    "\n",
    "engine.runAndWait()\n",
    "\n",
    "engine.setProperty(\"rate\", 200) # Speed (default ~200)\n",
    "\n",
    "engine.setProperty(\"volume\", 1.0) # Volume (0.0 to 1.0)\n",
    "\n",
    "#List available voices\n",
    "\n",
    "voices = engine.getProperty(\"voices\")\n",
    "\n",
    "for i, voice in enumerate (voices):\n",
    "\n",
    "    print(f\"Voice {i}: {voice.name} - {voice.id}\")\n",
    "\n",
    "#Set a specific voice\n",
    "\n",
    "engine.setProperty(\"voice\", voices[0].id) # Change index to select another voice\n",
    "engine.say(\"Welcome to AI with a different voice.\")\n",
    "engine.runAndWait()\n",
    "\n",
    "engine.setProperty(\"voice\", voices[1].id) # Change index to select another voice\n",
    "engine.say(\"Welcome to AI with a different voice.\")\n",
    "engine.runAndWait()\n",
    "\n",
    "engine.setProperty(\"voice\", voices[2].id) # Change index to select another voice\n",
    "engine.say(\"Welcome to AI with a different voice.\")\n",
    "engine.runAndWait()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO0xOthioZSKH9Lx7Piia8S",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
